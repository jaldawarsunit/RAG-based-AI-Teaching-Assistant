import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import joblib
import requests

def create_embedding(text_list):
    r=requests.post("http://localhost:11434/api/embed",json={
        "model":"bge-m3",
        "input":text_list
    })
    embedding=r.json()['embeddings']
    return embedding

def inference(prompt):
    r=requests.post("http://localhost:11434/api/generate",json={
        # "model":"deepseek-r1",
        "model":"llama3.2",
        "prompt":prompt,
        "stream":False
    })
    response=r.json()
    # print(response)
    return response


df=joblib.load("embeddings.joblib")

incoming_query=input("Ask a Question: ")


question_embedding=create_embedding([incoming_query])[0]

# a = create_embedding(["Hello, how are you?", "I am fine, thank you."])
# print(a)

#find similartiry of question embiding with other ebidding
# 2dimendstional vector
# print(np.vstack(df['embedding'].values))
# print(np.vstack(df['embedding']).shape)

similarities=cosine_similarity(np.vstack(df['embedding']),[question_embedding]).flatten()
# print(similarities)
top_results = 5
max_indx= similarities.argsort()[::-1][0:3]
# print(max_indx) 
new_df=df.iloc[max_indx]
# print(new_df[["title","number","text"]])

prompt=f'''i am teaching python using one shot taught by code with harry youtuber. Here are video subtitle chunks containing video title,video number,
start time in second,end time in seconds,the text at that time:

{new_df[["title","number","start","end","text"]].to_json(orient="records")}
--------------------------------
"{incoming_query}"
User asked this question related to the video chunks, you hae to answer in a human way (dont mention the above format,its just for you) where and how much content is taught in which video (in which video and at what timestamp) and guide the user to go to that particular video. If user asked unrelated question, tell him that you can only answer questions related to the course
'''

with open("prompt.txt","w") as f:
    f.write(prompt)

response = inference(prompt)["response"]
print(response)

with open("response.txt","w") as f:
    f.write(response)


# print(inference(prompt))
# for index, item in new_df.iterrows():
#     print(index,item["title"],item["number"],item["text"],item["start"],item["end"])
